{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('../data/processed/processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_not_in_training = ['StartTime', 'Dir', 'Proto', 'State', 'Label', 'SrcAddr', 'Sport', 'DstAddr', 'Dport', 'sTos', 'dTos', 'is_fwd' ]\n",
    "feature_x = feature_df.drop(columns=cols_not_in_training).to_numpy()\n",
    "feature_y = feature_df['Label'].to_numpy()\n",
    "\n",
    "malicious_df = feature_df.loc[feature_df['Label'] == 1].reset_index(drop=True)\n",
    "malicious_x = malicious_df.drop(columns=cols_not_in_training).to_numpy()\n",
    "malicious_y = malicious_df['Label'].to_numpy()\n",
    "\n",
    "benign_df = feature_df.loc[feature_df['Label'] == 0].reset_index(drop=True)\n",
    "benign_x = benign_df.drop(columns=cols_not_in_training).to_numpy()\n",
    "benign_y  = benign_df['Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def perform_predict(clf, X_train, X_test, y_train, y_test):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = malicious_x[:10]\n",
    "Y = malicious_y[:10]\n",
    "\n",
    "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# for train_index, test_index in kf.split(X, Y):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = Y[train_index], Y[test_index]\n",
    "#     clf_2 = svm.OneClassSVM(kernel=\"rbf\", gamma='scale', cache_size=400, nu=0.01)\n",
    "#     scaler_2 = preprocessing.StandardScaler().fit(X_train)\n",
    "#     clf_2.fit(scaler_2.transform(X_train))\n",
    "#     result = clf_2.predict(scaler_2.transform(X_test))\n",
    "#     print((len([ res for res in result if res == 1])/len(result))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = []\n",
    "clf_list.append(svm.OneClassSVM(kernel=\"rbf\", gamma='scale', cache_size=400, nu=0.01))\n",
    "clf_list.append(make_pipeline(preprocessing.StandardScaler(), svm.OneClassSVM(kernel=\"rbf\", gamma='scale', cache_size=400, nu=0.01)))\n",
    "clf_list.append(make_pipeline(preprocessing.RobustScaler(), svm.OneClassSVM(kernel=\"rbf\", gamma='scale', cache_size=400, nu=0.01)))\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test #0: 0.0%\n",
      "Test #1: 50.0%\n",
      "Test #2: 50.0%\n",
      "Test #3: 100.0%\n",
      "Test #4: 100.0%\n",
      "Accuracy: 60.00 (+/- 0.75)\n",
      "Test #0: 0.0%\n",
      "Test #1: 0.0%\n",
      "Test #2: 0.0%\n",
      "Test #3: 50.0%\n",
      "Test #4: 0.0%\n",
      "Accuracy: 10.00 (+/- 0.40)\n",
      "Test #0: 50.0%\n",
      "Test #1: 0.0%\n",
      "Test #2: 0.0%\n",
      "Test #3: 100.0%\n",
      "Test #4: 100.0%\n",
      "Accuracy: 50.00 (+/- 0.89)\n"
     ]
    }
   ],
   "source": [
    "for clf in clf_list:\n",
    "    scores = cross_val_score(clf, X, Y, scoring=\"accuracy\", cv=skf)\n",
    "    count = 0\n",
    "    for score in scores:\n",
    "        print(f'Test #{count}: {score*100}%')\n",
    "        count = count + 1\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean()*100, scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_predict(X_train, X_test):\n",
    "#     clf = svm.OneClassSVM(kernel=\"rbf\", gamma='scale', cache_size=8000, nu=0.01)\n",
    "#     scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# #     scaler = preprocessing.RobustScaler().fit(X_train)\n",
    "#     print(f'Training: {get_percentage(clf.fit_predict(scaler.transform(X_train)))}%')\n",
    "#     benign_test = benign_df.to_numpy()\n",
    "#     real_acc_results = clf.predict(scaler.transform(benign_test))\n",
    "# #     real_df = pd.DataFrame(data={'Results': real_acc_results})\n",
    "# #     print(real_df['Results'].value_counts())\n",
    "# #     print(real_df.head(10))\n",
    "#     print(f'Real Accuracy: {get_percentage(real_acc_results, False)}%' )\n",
    "#     test_result = clf.predict(scaler.transform(X_test))\n",
    "#     return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_decision(X_train, X_test):\n",
    "#     clf = svm.OneClassSVM(kernel=\"rbf\", gamma='scale', cache_size=5000)\n",
    "#     scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# #     scaler = preprocessing.RobustScaler().fit(X_train)\n",
    "#     clf.fit(scaler.transform(X_train))\n",
    "#     return np.sum(clf.score_samples(scaler.transform(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_percentage(arr, is_test=True):\n",
    "#     total = len(arr)\n",
    "#     count = 0\n",
    "#     if is_test:\n",
    "#         for item in arr:\n",
    "#             if item == 1:\n",
    "#                 count = count + 1\n",
    "#     else:\n",
    "#         for item in arr:\n",
    "#             if item == -1:\n",
    "#                 count = count + 1\n",
    "#     return (count/total * 100)\n",
    "#     print(f'Percentage: {(count/total * 100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benign_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = feature_df.iloc[:200000].to_numpy()\n",
    "# kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# add = 0\n",
    "# score = []\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     start = time.time()\n",
    "#     result = get_predict(X_train, X_test)\n",
    "#     score.append(result)\n",
    "# for single_test in score:\n",
    "#     print(f'Test: {get_percentage(single_test)}%')\n",
    "\n",
    "# for s in score:\n",
    "#     add = add + get_percentage(s)\n",
    "# mean = add/len(score)\n",
    "# print(f'Mean Test: {mean}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     results.append(get_predict(X_train, X_test))\n",
    "#     print('One Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_percentage(clf_2.predict(scaler_2.transform(benign_df.to_numpy())), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_percentage(clf_2.predict(scaler_2.transform(final_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data = feature_df.to_numpy()\n",
    "# clf_2 = svm.OneClassSVM(kernel=\"rbf\", gamma='scale', cache_size=8000, nu=0.01)\n",
    "# scaler_2 = preprocessing.StandardScaler().fit(final_data)\n",
    "# clf_2.fit(scaler_2.transform(final_data))\n",
    "# pickle.dump(clf_2, open('./ultimate_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute mean\n",
    "# kf = KFold(n_splits=3, shuffle=True)\n",
    "# kf = StratifiedKFold(n_splits=3, shuffle=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('RDM-env': venv)",
   "language": "python",
   "name": "python38164bitrdmenvvenv4b617ac6a3c04225a7e20584d0a1c7e8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
